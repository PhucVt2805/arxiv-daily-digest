from fastapi import FastAPI
from contextlib import asynccontextmanager
from typing import List

from src.database import init_database
from src.crawler.scraper import ArxivScraper
from src.utils.log_config import setup_logging, get_logger
from src.processor import VectorProcessor
from src.model import ArxivPaper

logger = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    setup_logging()
    global logger
    logger = get_logger("MainApp")

    logger.info("ğŸš€ The server is starting up...")

    try:
        await init_database()
    except Exception as e:
        logger.critical(f"Failed to initialize the database: {e}")
        raise e
    logger.info("ğŸ”„ Activate the Crawler Pipeline to start...")

    try:
        scraper = ArxivScraper()
        processor = VectorProcessor()

        papers = scraper.get_paper(topics=["AI", "CL", "CV", "CL"], days_back=3)
        new_papers = await scraper.save_to_db(papers)

        if new_papers:
            await processor.process_and_index(new_papers)
            logger.info(f"ğŸ“Š Pipeline complete: {len(new_papers)} new post is ready for chat.")
        else:
            logger.info("âš ï¸ There are no new posts to process.")
            
    except Exception as e:
        logger.error(f"âŒ Pipeline error: {e}", exc_info=True)
    logger.info("âœ… The system is ready to receive requests!")
    
    yield

    logger.info("ğŸ›‘ Server is off...")

app = FastAPI(lifespan=lifespan)
@app.get("/")
def read_root():
    return {"status": "running", "service": "Arxiv Agent"}

@app.get("/news/latest")
async def get_latest_news():
    papers = await ArxivPaper.find_all().sort("-published_date").limit(20).to_list()
    return papers

from fastapi.responses import StreamingResponse
import asyncio

@app.post("/chat/stream")
async def chat_stream(body: dict):
    async def fake_generator():
        mock_text = f"TÃ´i Ä‘Ã£ nháº­n cÃ¢u há»i: '{body['message']}' vá» bÃ i bÃ¡o {body['paper_id']}. \n\nÄÃ¢y lÃ  cÃ¢u tráº£ lá»i giáº£ láº­p tá»« Backend..."
        for word in mock_text.split():
            yield word + " "
            await asyncio.sleep(0.1)
            
    return StreamingResponse(fake_generator(), media_type="text/plain")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run('src.main:app', host='0.0.0.0', port=8000, reload=True)